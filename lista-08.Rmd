---
title: "Lista-08"
author: "Panosso, AR"
date: "17-12-2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      error = FALSE,
                      warning = FALSE)
```

## Roteiro para análise diagnóstico

### Carregando Pacotes
```{r}
library(tidyverse)
library(agricolae)
library(ExpDes.pt)
library(nortest)
library(lawstat)
library(MASS)
library(HH)
source("../minhas-funcoes.R")
theme_set(theme_bw()) # setar o tema padrão para o ggplot
```

### Entrada de Dados

Para o exemplo, ler o arquivo **producao-da-cultura.xlsx**. Não se esqueça de deixar os tratamentos como fator.

```{r}
data_set <- read_rds("../DATA/producao-de-cultura.rds")
glimpse(data_set)
```

### Estatística para os Tratamentos

Estatísticas resumos por tratamento, gráficos histograma, boxplot e qqnorm.

#### Estatística Descritiva

```{r}
data_set |> 
  group_by(trat) |> 
  summarise(
    n = n(),
    media = mean(prod,na.rm = TRUE),
    desv_pad = sd(prod,na.rm = TRUE),
    erro_pad = desv_pad/sqrt(n)
  )
```

#### Histograma da variável resposta

```{r}
data_set |> 
  ggplot(aes(x=prod, y=..density..)) +
  geom_histogram(color="black", fill="lightgray") +
  labs(y = "Densidade", x = "Produção da Cultura")
```


#### Gráfico Boxplot

Criar o boxplot ordenados por valor de média da variável alvo.

```{r}
data_set |> 
  group_by(trat) |> 
  mutate(
    media = mean(prod, na.rm = TRUE),
    trat = trat |> as_factor() |> fct_reorder(media)
  ) |> 
  ggplot(aes(x=trat, y=prod)) +
  geom_boxplot(fill="lightgray") + 
  geom_jitter(color="blue2")
  labs(x="Tratamentos", y="Produção da Cultura (kg/parcela)") 
  
```

#### QQ-plot

```{r}
data_set |> 
  ggplot(aes(sample = prod)) +
  stat_qq() +
  stat_qq_line(color = "blue") +
  labs(x="Quantil teórico", y="Quantil observado")
```

### Extração das colunas para realizar a analise de variância.

Para realizar a construção do modelo para ANOVA deve-se extrair todas as colunas envolvidas na definição do modelo da anova.

```{r}
y <- data_set |> pull(prod)
trat <- data_set |>  pull(trat) |> as_factor()
is.factor(trat) # verificando se trat é fator
is.numeric(y) # verificando se y é numérico
```

### Definição do modelo

O modelo da análise a ser utilizado será o mais simples (Delineamento Inteiramente Casualizado).

$$y_{ij} = \mu + \tau_i + \epsilon_{ij}$$

Para analisar as pressuposições (Normalidade dos erros e Homocedasticidade), precisamos dos erros, desvios do modelo portanto, utilizamos a função `aov` - para construir o modelo da análise de variância. O resumo da análise com o quadro da ANOVA pode ser acessado com a função `anova`.

```{r}
mod <- aov(y~trat);mod
anova(mod)
```

### Normalidade dos resíduos

Uma vez o modelo salvo, precisamos extrair os resíduos, erros, para testar as pressuposições, estudar os outliers e definir possíveis transformações aos dados.

#### Extrair os resíduos e valores preditos
```{r}
rs <- rstudent(mod)
```


#### Definir o data.frame contendo as colunas extraídas, os resíduos e valores preditos
```{r}

```


#### Histograma
```{r}

```


#### QQ-plot
```{r}

```

#### Teste de normalidade

Testando a normalidade dos resíduos e realizando a análise gráfica dos mesmos `install.packages("nortest")` caso necessário.

```{r}
# Shapiro-Wilks
shapiro.test(rs)

# Kolmogorov-Smirnov
lillie.test(rs)

# Anderson-Darlin
ad.test(rs)

# Cramer-von Mises
cvm.test(rs)
```


### Estudo de outliers

Os Resíduos brutos são aqueles calculados diretamente a partir do modelo da análise de variância definido, e podem ser acessados com a função `residual``.

Resíduos Padronizados (são os resíduo brutos dividido pelo erro padrão da estimativa dos resíduos). Se os erros têm distribuição normal, então aproximadamente 95% dos resíduos padronizados devem estar no intervalo de (-2,2). Resíduos fora desse intervalo podem indicar a presença de outliers. Utilize a função `rstandard` para calcular esses resíduos. 

Resíduos Studentizados são considerados independentes pelo fato de serem resíduos decorrentes de procedimento leave-one-out. Para todos os efeitos, é como se o resíduo padronizado da observação i fosse calculado removendo-se o i-ésimo registro e ajustado o modelo. vantagem é que esses resíduos tem variância constante, (Var(rs) = 1) tornando muito mais fácil a procupra de outliers, ou seja, observações distantes das demais.

Para ilustrar qual resíduo utilizar na análise de resíduos, representar graficamente este
gráfico usando os três resíduos, numa mesma figura e observar o que acontece.

```{r}
res <- residuals(mod)
rp <- rstandard(mod)
rs <- rstudent(mod)
yp <- predict(mod) 

data.frame(res,rp,rs,yp) |> 
  pivot_longer(res:rs,names_to = "residuo", values_to = "valor") |> 
  ggplot(aes(x=yp, y=valor, color = residuo)) +
  geom_point() +
  facet_wrap(~residuo, scale = "free") +
  theme(
    legend.position = "top"
  )
```

#### Construir o gráfico dos resíduos studentizados vs valores preditos

```{r}
diagnostico |> 
  ggplot(aes(x=yp,y=rs))+
  geom_point()
```


### Homogeneidade das variâncias (homocedasticidade)
Quatro testes podem ser empregados, o teste de Levene, o teste de Brown-Forsythe o teste de Bartlett e Box-Cox

#### Testes de homocedasticidade

```{r}
# Teste clássico de Levene
levene.test(y,trat,location="mean")

# Teste Brown-Forsythe
levene.test(y,trat)

#também disponivél no pacote HH
#install.packages("HH")
hov(y~trat)

# Teste de Bartlett
bartlett.test(y~trat)
```


### Transformação - Bartlett

Se o teste for significativo, ou seja, rejeitamos a hipótese de homocedasticidade, os dados são heterocedasticos. A falta de homogenidade das variâncias pode ser regular ou irregular:

HETEROCEDASTICIDADE IRREGULAR: devemos utilizar um teste não-paramétrico.
HETEROCEDASTICIDADE REGULAR: existe uma relação entre a média e a variância utlizamos a tranformação 

$$yt = y^{(1-b/2)}$$ 

onde b é coeficiente angular do modelo de regressão linear entre o log da variância e o log da média de cada tratamento.

```{r}
# 1) Cálculo do log das variâncias e das médias por tratamentos
df_aux<-diagnostico |> 
  group_by(trat) |> 
  summarise(
    log_media=log(mean(y,na.rm=TRUE)),
    log_variancia=log(var(y,ns.rm=TRUE)),
    
  )
# 2) Análise de regressão linear simples de LV em função de LM
mod_reg<-lm(log_variancia~log_media,
            data=df_aux
# 4) Transformação, se necessária:
b<- mod_reg$coefficients_re
yt<-y^(1-b/2)
```

#### Transformação - Box - Cox
A transformação Box-Cox é uma das possíveis formas de contornar o problema de dados que não obedecem os pressupostos da análise de variância, como normalidade dos dados.

```{r}
boxcox(mod,seq(0,2,0.2))
```
  + se lambda não difere de 1: Dados são homocedásticos  
  + se lambda difere de 1 (Transformação:

$$\begin{cases}
yt = y^\lambda: \text{se lambda difere de 0} \\
yt = \log{y}: \text{se lambda não difere de 0} 
\end{cases}$$

## A análise de variância

### Definição do modelo finAL
```{r}
modelo_final<-aov(yt~trat)
anova(modelo_final)
```

### Cálculo do CV

$$CV = \frac{\sqrt{QM_{res}}}{\hat{m}}$$
```{r}
sqr<-deviance(modelo_final)
glr<-df.residual(modelo)
qmr<-sqr/glr
media<-mean(yt,na.rm=TRU)
100*sqrt(qmr/media)
```

### Procedimento Para Comparação Múltiplas

Quando não se tem qualquer informação a priori sobre os tratamentos, sugere-se "comparações múltiplas". Os testes mais comuns para Comparações Múltiplas são: 

  + Tukey; 
  + Duncan;  
  + Student Newman Keuls (SNK);
  + t Student (LSD);

#### Teste de Tukey

Utilizando o Pacote Agricolae

```{r}
HDS.test(modelo_final,"trat"
```

Utilizando o Pacote ExpDes.pt

```{r}

```

#### Teste de Duncan
Utilizando o Pacote Agricolae

```{r}

```

Utilizando o Pacote ExpDes.pt

```{r}

```
#### Teste de Student-Newman-Keuls

Utilizando o Pacote Agricolae

```{r}

```

Utilizando o Pacote ExpDes.pt

```{r}

```

#### Teste t-Student (LSD)
Utilizando o Pacote Agricolae

```{r}

```

Utilizando o Pacote ExpDes.pt

```{r}

```

